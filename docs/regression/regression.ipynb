{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca606dc",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "In other words, you need to find a function that maps some features or variables to others sufficiently well.\n",
    "\n",
    "The dependent features are called the dependent variables, outputs, or responses. The independent features are called the independent variables, inputs, regressors, or predictors.\n",
    "\n",
    "\n",
    "Itâ€™s a common practice to denote the outputs with ğ‘¦ and the inputs with ğ‘¥. If there are two or more independent variables, then they can be represented as the vector ğ± = (ğ‘¥â‚, â€¦, ğ‘¥áµ£), where ğ‘Ÿ is the number of inputs.\n",
    "\n",
    "When implementing linear regression of some dependent variable ğ‘¦ on the set of independent variables ğ± = (ğ‘¥â‚, â€¦, ğ‘¥áµ£), where ğ‘Ÿ is the number of predictors, you assume a linear relationship between ğ‘¦ and ğ±: ğ‘¦ = ğ›½â‚€ + ğ›½â‚ğ‘¥â‚ + â‹¯ + ğ›½áµ£ğ‘¥áµ£ + ğœ€. This equation is the regression equation. ğ›½â‚€, ğ›½â‚, â€¦, ğ›½áµ£ are the regression coefficients, and ğœ€ is the random error.\n",
    "\n",
    "Linear regression calculates the estimators of the regression coefficients or simply the predicted weights, denoted with ğ‘â‚€, ğ‘â‚, â€¦, ğ‘áµ£. These estimators define the estimated regression function ğ‘“(ğ±) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + â‹¯ + ğ‘áµ£ğ‘¥áµ£. This function should capture the dependencies between the inputs and output sufficiently well.\n",
    "\n",
    "The estimated or predicted response, ğ‘“(ğ±áµ¢), for each observation ğ‘– = 1, â€¦, ğ‘›, should be as close as possible to the corresponding actual response ğ‘¦áµ¢. The differences ğ‘¦áµ¢ - ğ‘“(ğ±áµ¢) for all observations ğ‘– = 1, â€¦, ğ‘›, are called the residuals. Regression is about determining the best predicted weightsâ€”that is, the weights corresponding to the smallest residuals.\n",
    "\n",
    "To get the best weights, you usually minimize the **sum of squared residuals (SSR)** for all observations ğ‘– = 1, â€¦, ğ‘›: \n",
    "\n",
    "$SSR = \\sum_i (y_i-f(x_i))^2$\n",
    "\n",
    "This approach is called the method of **ordinary least squares**.\n",
    "\n",
    "\n",
    "## Multiple Linear Regression\n",
    "\n",
    "Multiple or multivariate linear regression is a case of linear regression with two or more independent variables.\n",
    "\n",
    "If there are just two independent variables, then the estimated regression function is ğ‘“(ğ‘¥â‚, ğ‘¥â‚‚) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚. It represents a regression plane in a three-dimensional space. The goal of regression is to determine the values of the weights ğ‘â‚€, ğ‘â‚, and ğ‘â‚‚ such that this plane is as close as possible to the actual responses, while yielding the minimal SSR.\n",
    "\n",
    "The case of more than two independent variables is similar, but more general. The estimated regression function is ğ‘“(ğ‘¥â‚, â€¦, ğ‘¥áµ£) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + â‹¯ +ğ‘áµ£ğ‘¥áµ£, and there are ğ‘Ÿ + 1 weights to be determined when the number of inputs is ğ‘Ÿ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6ef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa86f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
